}
# Use Map to apply the function to each sublist
result <- Map(extract_values, seq_along(Namebottle),Namebottle)
# Combine the result into a dataframe
final_dataset <- do.call(rbind, result)
final_dataset <- as.data.frame(final_dataset)
colnames(final_dataset) <- c("List", "Sublist", "Content")
# Print final_dataset
print(final_dataset)
# Use Map to apply the function to each sublist
result <- Map(extract_values, seq_along(Namebottle),Namebottle)
# Combine the result into a dataframe
final_dataset <- do.call(rbind, result)
final_dataset <- as.data.frame(final_dataset)
colnames(final_dataset) <- c("List", "Sublist", "Content")
# Create a function to extract indices and values from a sublist
extract_values <- function(index, sublist) {
n <- length(sublist)
if (n == 0) {
return(list(index, NA, NA))
} else {
indices <- rep(index, n)
return(Map(c, indices, seq_along(sublist), sublist))
}
}
# Use Map to apply the function to each sublist
result <- unlist(Map(extract_values, seq_along(Namebottle), Namebottle), recursive = FALSE)
# Combine the result into a dataframe
final_dataset <- do.call(rbind, result)
final_dataset <- as.data.frame(final_dataset)
colnames(final_dataset) <- c("List", "Sublist", "Content")
gc()
rm(list = ls())
gc()
close(file_connection)
gc()
gc()
## 1.2. Load the data------------
Parish <- read_csv("Day2/data/Parishes.csv")
library(quanteda)
library(tidyverse)
library(quanteda.textstats)
library(quanteda.textmodels)
library(quanteda.textplots)
library(tm)
library(topicmodels)
library(syuzhet)
library(RColorBrewer)
## 1.2. Load the data------------
Parish <- read_csv("Day2/data/Parishes.csv")
## 2.3. Extract the text column ------
# We'll work with the UK data first, and then you'll repeat the process with the Scotland data on your own later in this block.
# Subset the text column and save it as an object:
ParishText<-Parish$text
# Prepare the data for analysis, creating and cleaning a tm Corpus object:
ParishCorpus <- VCorpus(VectorSource(ParishText))# transform our data set in a corpus
ParishCorpus<- tm_map (ParishCorpus, content_transformer(tolower))# remove capitalised letters
ParishCorpus <- tm_map (ParishCorpus, removePunctuation)# remove punctuation
ParishCorpus<- tm_map (ParishCorpus, removeWords, stopwords('english')) # remove English stopwords
ParishCorpus <- tm_map (ParishCorpus, removeWords, c('s', 't', '@\\w+', 'http.+ |http.+$','amp')) # remove specific words/symbols
ParishCorpus<- tm_map (ParishCorpus, removeNumbers)# remove numbers
ParishCorpus <- tm_map (ParishCorpus, stripWhitespace) # remove multiple white spaces
# 3. Topic Modelling=================================
## 3.1. Create a document term matrix (dtm) of the corpus------
# A DTM is a mathematical matrix that describes the frequency of terms that occur in a collection of documents.
# Rows correspond to documents in the collection and columns correspond to terms.
LdaDtmParish <- DocumentTermMatrix(ParishCorpus)
gc()
gc()
gc()
gc()
## 3.4. Create a term frequency matrix --------------
LdaDtmParishMx<- as.matrix(LdaDtmParish)
## 3.5. LDA topic modelling-------------------------------------
### 3.5.1. Create a matrix k 5--------------
#Create a matrix for LDA analsyis, defining the number of topics (k=5)
P_lda <- LDA(LdaDtmParish, k=5, control=list(seed=1234))
View(LdaDtmParish)
# Remove rows with all zero values
LdaDtmParish_processed <- LdaDtmParish[rowSums(LdaDtmParish != 0) > 0, ]
LdaDtmParish_matrix <- as.matrix(LdaDtmParish)
library(syuzhet)
library(vader)
library(tidyverse)
library(wordcloud)
library(tm)
# Import the dataset
whiskyReview1<-read_csv("Day3/export/data/ReviewWithDistilleriesInfo.csv")
wiskyReview2<-read_csv("Day1/DataWrangling/Data/scotch_review_manual_clean.csv")
View(wiskyReview2)
Whisky1 <- whiskyReview1$Reviews %>%
lapply(get_vader)
#our full dataset are too big so we are going to work on a subset
whiskyReview1S<-sample_n(whiskyReview1, 300, set.seed=1234)
## 2.2. Calculate sentiment scores with VADER --------
Whisky1 <- whiskyReview1S$Reviews %>%
lapply(get_vader)# lapply= apply across the data set
library(parallel)
library(doParallel)
install.packages(doParallel)
install.packages("doParallel")
library(doParallel)
# Initialize a cluster with desired number of workers
cl <- makeCluster(4, type = 'PSOCK', outfile = '')
# Register the cluster for parallel computation
registerDoParallel(cl)
result <- foreach(review = Whisky1) %dopar% {
get_vader(review)
}
## 2.2. Calculate sentiment scores with VADER --------
Whisky1 <- whiskyReview1S$Reviews
# Apply the function get_vader in parallel
result <- foreach(review = Whisky1) %dopar% {
get_vader(review)
}
library(vader)
result <- foreach(review = Whisky1) %dopar% {
get_vader(review)
}
# Apply the function get_vader in parallel
result <- foreach(review = Whisky1) %dopar% {
Vader::get_vader(review)
}
vader::get_vader(review)
# Stop the cluster
stopCluster(cl)
# Combine the results if needed
combined_result <- do.call(rbind, result)
# Apply the function get_vader in parallel
result <- foreach(review = Whisky1) %dopar% {
vader::get_vader(review)
}
# Initialize a cluster with desired number of workers
cl <- makeCluster(4, type = 'PSOCK', outfile = '')
# Register the cluster for parallel computation
registerDoParallel(cl)
# Apply the function get_vader in parallel
result <- foreach(review = Whisky1) %dopar% {
vader::get_vader(review)
}
library(foreach)
library(doParallel)
library(Vader)
library(vader)
# Initialize a cluster
cl <- makeCluster(detectCores())  # Use all available cores
registerDoParallel(cl)
# Apply sentiment analysis in parallel
result <- foreach(review = whiskyReview1S$Reviews) %dopar% {
get_vader(review)
}
# Initialize a cluster
cl <- makeCluster(detectCores())  # Use all available cores
registerDoParallel(cl)
# Apply sentiment analysis in parallel
result <- foreach(review = whiskyReview1S$Reviews) %dopar% {
vader::get_vader(review)
}
install.packages("brms")
library(brms)
install.packages("bayesplot")
detach("package:brms", unload = TRUE)
install.packages("bayesplot")
install.packages("bayesplot")
install.packages("extraDistr")
library(extraDistr)
library(bayesplot)
#ok now that we have cleaned the unstructured data let's do some work on the structured dataset
# Create your dataframe
Distilleries<-read.csv("Day1/DataWrangling/data/scotches.csv")
library(tidyverse)# The tidyverse is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.https://www.tidyverse.org/
library(data.table)#data.table is an R package that provides an enhanced version of data.frames, which are the standard data structure for storing data in base R https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html
library(reshape2)
library(fuzzyjoin)
get_info <- function(row, column_names) {
selected_columns <- column_names[row == 1]
if (length(selected_columns) > 0) {
return(paste(selected_columns, collapse = ", "))
} else {
return("None")
}
}
Colour <- names(Distilleries)[3:16]
Nose<-names(Distilleries)[16:28]
Body<-names(Distilleries)[29:36]
Palate<-names(Distilleries)[37:51]
Fin<-names(Distilleries)[52:70]
Area<-names(Distilleries)[77:85]
# Add a new column "colourcheck" which contains the names of specified columns where the value is 1, separated by comma
Distilleries$colour <- apply(Distilleries[, Colour], 1, get_info, column_names = Colour)
Distilleries$nose <- apply(Distilleries[, Nose], 1, get_info, column_names = Nose)
Distilleries$body <- apply(Distilleries[, Body], 1, get_info, column_names = Body)
Distilleries$palate <- apply(Distilleries[, Palate], 1, get_info, column_names = Palate)
Distilleries$fin <- apply(Distilleries[, Fin], 1, get_info, column_names = Fin)
Distilleries$area <- apply(Distilleries[, Area], 1, get_info, column_names = Area)
ScotDist<-Distilleries[,c(1:2,71:76,86:95)]
Colour <- names(Distilleries)[3:16]
Nose<-names(Distilleries)[16:28]
Body<-names(Distilleries)[29:36]
Palate<-names(Distilleries)[37:51]
Fin<-names(Distilleries)[52:70]
Area<-names(Distilleries)[77:85]
Distilleries$colour <- apply(Distilleries[, Colour], 1, get_info, column_names = Colour)
Distilleries$nose <- apply(Distilleries[, Nose], 1, get_info, column_names = Nose)
Distilleries$body <- apply(Distilleries[, Body], 1, get_info, column_names = Body)
Distilleries$palate <- apply(Distilleries[, Palate], 1, get_info, column_names = Palate)
Distilleries$fin <- apply(Distilleries[, Fin], 1, get_info, column_names = Fin)
Distilleries$area <- apply(Distilleries[, Area], 1, get_info, column_names = Area)
ScotDist<-Distilleries[,c(1:2,71:76,86:95)]
View(Distilleries)
ScotDist<-Distilleries[,c(1:2,71:76,86:94)]
#Remove all the .1.2 from repeating column names
ScotDist <- mutate(ScotDist, across(where(is.character), ~gsub(".1|.2", "", .)))
write_csv(ScotDist, "Day1/DataWrangling/Export/ScotDistilleries.csv")
scotch_review <- read_csv("Day1/DataWrangling/data/scotch_review_manual_clean.csv")
Operating_whisky_distilleries <- read_csv("Day1/DataWrangling/data/List_of_whisky_distilleries_in_Scotland_manual_clean.csv")
summary(scotch_review)
unique(scotch_review$price)
scotch_df <- scotch_review %>%
mutate(category = as.factor(category))
summary(scotch_df)
unique(scotch_review$name)
unique(Operating_whisky_distilleries$Distillery)
df <- scotch_df %>% fuzzy_inner_join(Operating_whisky_distilleries,by=c("name" = "Distillery"),match_fun = str_detect) %>% select(-description)
df_2 <- df %>% group_by(name) %>%
reframe(#mean_price = mean(price),
#log_mean_price = log(mean_price),
price = price,
log_price = log(price),
review.point = review.point,
Owner = Owner,
category = category,
Distillery = Distillery,
Location = Location,
Region = Region,
Founded = Founded#,
# mean_review.point = mean(review.point)
) %>%
ungroup() %>%
mutate(ABV = as.numeric(gsub(".*?(\\d+\\.?\\d*)%.*", "\\1", name)), # creating ABV varaible (alcohol strength) from whisky name.
# category = as.factor(category),
# Distillery = as.factor(Distillery),
# Founded = as.factor(Founded),
# Location = as.factor(Location),
# Region = as.factor(Region),
# n_distillery = count(Distillery)
#log_price = log(price)
# uncomment to include - but figured this stuff could be left for the attendees
) %>%
add_count(Distillery) %>%
mutate(n_Distillery = n) %>%
distinct() %>% # There are just 2 duplicates in the data, so simpler to remove as apposed to doing anything more sophisticated, as likely just human error.
select(-n)
#filter(n_Distillery > 1) %>%
na.omit()
df_2 <- df %>% group_by(name) %>%
reframe(#mean_price = mean(price),
#log_mean_price = log(mean_price),
price = price,
log_price = log(price),
review.point = review.point,
Owner = Owner,
category = category,
Distillery = Distillery,
Location = Location,
Region = Region,
Founded = Founded#,
# mean_review.point = mean(review.point)
) %>%
ungroup() %>%
mutate(ABV = as.numeric(gsub(".*?(\\d+\\.?\\d*)%.*", "\\1", name)), # creating ABV varaible (alcohol strength) from whisky name.
# category = as.factor(category),
# Distillery = as.factor(Distillery),
# Founded = as.factor(Founded),
# Location = as.factor(Location),
# Region = as.factor(Region),
# n_distillery = count(Distillery)
#log_price = log(price)
# uncomment to include - but figured this stuff could be left for the attendees
) %>%
add_count(Distillery) %>%
mutate(n_Distillery = n) %>%
distinct() %>% # There are just 2 duplicates in the data, so simpler to remove as apposed to doing anything more sophisticated, as likely just human error.
select(-n)
summary(duplicated(df_2))
# Investigating ABV variables
df_2 %>% select(name, ABV) %>%
arrange(desc(ABV))
unique(df_2$ABV)
hist(df_2$ABV)
#overall summary view
summary(df_2)
write.csv(df_2, "Day1/DataWrangling/Export/Whisky_distillery_data.csv")
# Step 1: Read CSV file
data <- read_csv("Day3/export/data/ReviewWithDistilleriesInfo.csv")
library(syuzhet)
sentiment_scores <- get_nrc_sentiment(data$Reviews)
summary(sentiment_scores)
library(tidyverse)
library(rvest)
# The firs thing to do is figuring out where are we starting from. In our case is a website dedicated to whiskys lovers that allows you to review and rate single bottle of whisky. Because we are interested only in the whisky coming from Scotland we are actually going to start from a page that collect all the Scottish distilleries.
# Our website has a hierarchical structure
# The first page
Homepage <- 'https://www.connosr.com/scotch-whisky'
# Read the pages ===================
get.article.links <- function(x){
links <- read_html(x) %>%
html_nodes('.name') %>%
html_attr('href')
}
DistLinks <- map(Homepage, get.article.links)
head(DistLinks)
length(DistLinks)
# So we need to use the flatten function to deal with this
DistLinksFlat <- DistLinks %>%
flatten()
head(DistLinksFlat)
length(DistLinksFlat)
Links <-unlist(DistLinksFlat)
FullLinks<- paste0("https://www.connosr.com", Links)
#Get Names distilleries
get.dist.names <- function(x){
links <- read_html(x) %>%
html_nodes('.name') %>%
html_text()
}
DistNames <- map(Homepage, get.dist.names)
head(DistNames)
length(DistNames)
# So we need to use the flatten function to deal with this
DistNamesFlat <- DistNames %>%
flatten()
head(DistNamesFlat)
length(DistNamesFlat)
DistNames <-unlist(DistNames)
head(DistNames)
#Remove al letters at the start
# Remove initial letters followed by a space
cleanedNames <- sub("^\\w+\\s", "", DistNames)#using regex
#Get Notes
get.notes <- function(x){
links <- read_html(x) %>%
html_nodes('.align-right') %>%
html_text()
}
Notes <- map(Homepage, get.notes)
head(Notes)
# So we need to use the flatten function to deal with this
NotesFlat <- Notes %>%
flatten()
head(NotesFlat)
length(NotesFlat)
Notes<-unlist(NotesFlat)
head(Notes)
# Remove common tags:
cleanedNotes <- sub("Common tags: ", "", Notes)
unique(cleanedNotes)
#Get RateD
get.rate.dist <- function(x){
links <- read_html(x) %>%
html_nodes('.not-small-phone') %>%
html_text()
}
RateDist <- map(Homepage, get.rate.dist)
head(RateDist)
# So we need to use the flatten function to deal with this
RateDistFlat <- RateDist %>%
flatten()
head(RateDistFlat)
length(RateDistFlat)
RateDist<-unlist(RateDistFlat)
head(RateDist)
# Remove Average rating:
cleanedRateDist <- sub("Average rating: ", "", RateDist)
cleanedRateDist <-as.numeric(cleanedRateDist)
#now we go one level down ####
#Get link from links
get.bottle.link <- function(x){
links <- read_html(x) %>%
html_nodes('.name') %>%
html_attr('href')
}
BottleLinks <- map(FullLinks, get.bottle.link)
head(BottleLinks)
# So we need to use the flatten function to deal with this
BottleLinksFlat <- BottleLinks %>%
flatten()
head(BottleLinksFlat)
length(BottleLinksFlat)
BottleLinks <-unlist(BottleLinks)
FullLinksBottle<- paste0("https://www.connosr.com", BottleLinks)
#Get name from links
get.bottle.name <- function(x){
links <- read_html(x) %>%
html_nodes('.name') %>%
html_text()
}
BottleName<- map(FullLinks, get.bottle.name )
head(BottleName)
# So we need to use the flatten function to deal with this
BottleNameFlat <- flatten(BottleName)
head(BottleNameFlat)
length(BottleNameFlat)
BottleNames <-unlist(BottleNameFlat)
# get reviews
get.bottle.reviews <- function(x){
links <- read_html(x) %>%
html_nodes('.simple-review-content p') %>%
html_text()
}
BottleReview<- map(FullLinksBottle, get.bottle.reviews)
gc()
BottleName<- map(FullLinks, get.bottle.name )
BottleNameFlat <- flatten(BottleName)
head(BottleNameFlat)
length(BottleNameFlat)
BottleNames <-unlist(BottleNameFlat)
gc()
# get reviews
get.bottle.reviews <- function(x){
links <- read_html(x) %>%
html_nodes('.simple-review-content p') %>%
html_text()
}
BottleReview<- map(FullLinksBottle, get.bottle.reviews)
Try<-head(FullLinksBottle,3)
BottleReview<- map(Try, get.bottle.reviews)
View(BottleReview)
BottleReview<- map(FullLinksBottle, get.bottle.reviews)
#Merge together all reviews of each bottle
# Merge all sublists within each list
merged_list <- lapply(BottleReview, unlist)
merged_strings <- sapply(merged_list, function(x) paste(x, collapse = " "))
# Create a dataframe with one column named "review"
ReviewByBottle <- data.frame(review = merged_strings)
# Create a dataframe with the original vector and its index
WithBottleNames <- data.frame(BottleName = BottleNames, review= ReviewByBottle$review)
get.bottle.dist <- function(x){
links <- read_html(x) %>%
html_node('.data a') %>%
html_text()
}
BottleDist<- map(FullLinksBottle, get.bottle.dist)
head(BottleDist)
BottleDistFlat <- BottleDist %>%
flatten()
head(BottleDistFlat)
length(BottleDistFlat)
BottleDistFlat<-unlist(BottleDistFlat)
get.bottle.abv <- function(x){
links <- read_html(x) %>%
html_node('abbr+ .data') %>%
html_text()
}
BottleABV<- map(FullLinksBottle, get.bottle.abv)
get.bottle.abv <- function(x){
links <- read_html(x) %>%
html_node('abbr+ .data') %>%
html_text()
}
BottleABV<- map(FullLinksBottle, get.bottle.abv)
get.bottle.abv <- function(x){
links <- read_html(x) %>%
html_node('abbr+ .data') %>%
html_text()
}
BottleABV<- map(FullLinksBottle, get.bottle.abv)
get.bottle.rate <- function(x){
rate <- read_html(x) %>%
html_node('.happy') %>%
html_text()
}
BottleRate<- map(Try, get.bottle.rate)
head(BottleABV)
head(BottleRate)
get.bottle.rate <- function(x){
rate <- read_html(x) %>%
html_node('.happy') %>%
html_text()
}
BottleRate<- map(FullLinksBottle, get.bottle.rate)
# now we get the average score per bottle
get.bottle.rate <- function(x){
rate <- read_html(x) %>%
html_node('.happy') %>%
html_text()
}
BottleRate<- map(FullLinksBottle, get.bottle.rate)
BottleABVFlat <-BottleABV %>%
flatten()
get.bottle.abv <- function(x){
links <- read_html(x) %>%
html_node('abbr+ .data') %>%
html_text()
}
BottleABV<- map(FullLinksBottle, get.bottle.abv)
get.bottle.rate <- function(x){
rate <- read_html(x) %>%
html_node('.happy') %>%
html_text()
}
BottleRate<- map(FullLinksBottle, get.bottle.rate)
library(tidyverse)
library(rvest)
get.bottle.rate <- function(x){
rate <- read_html(x) %>%
html_node('.happy') %>%
html_text()
}
BottleRate<- map(FullLinksBottle, get.bottle.rate)
BottleRate<- map(FullLinksBottle, get.bottle.rate)
BottleRate<- map(FullLinksBottle, get.bottle.rate)
